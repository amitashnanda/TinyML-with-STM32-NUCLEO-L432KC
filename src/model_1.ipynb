{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from kerasbeats import prep_time_series, NBeatsModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "# from darts.models import NBEATSModel\n",
    "\n",
    "# from darts import TimeSeries, concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Activation, BatchNormalization, Dropout, Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, MaxPool1D, Flatten, Conv2D, MaxPooling2D\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import LSTM\n",
    "# from keras.utils import to_categorical\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from keras.layers import Bidirectional\n",
    "# from keras import optimizers\n",
    "# from keras.layers import Input, LSTM, Dense, TimeDistributed, Activation, BatchNormalization, Dropout, Bidirectional\n",
    "# from keras.layers import Conv1D, MaxPooling1D, MaxPool1D, Flatten, Conv2D\n",
    "# import pickle\n",
    "from sklearn.metrics import fbeta_score\n",
    "import tensorflow_model_optimization as tfmot\n",
    "# import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# directory = './Data/tinyml_contest_data_training'\n",
    "\n",
    "# data = {'Subject Number': [],\n",
    "#         'Label': [],\n",
    "#         'Index': [],\n",
    "#         'Bin'  : []}\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# rows, cols = (30213, 1251)\n",
    "# arr = [[0]*cols]*rows\n",
    "# print('row: ' + str(len(arr)))\n",
    "# print('col: ' + str(len(arr[0])))\n",
    "        \n",
    "        \n",
    "# print(df)\n",
    "# # iterate over files in\n",
    "# # that directory\n",
    "\n",
    "# filecnt = 0\n",
    "\n",
    "# for filename in os.scandir(directory):\n",
    "#     #if filename.is_file():\n",
    "#         #print(filename.path.replace('DeepLearning_for_ImagingFlowCytometry/data/TinyMl/tinyml_contest_data_training', '', 1))\n",
    "        \n",
    "#     filevals = []\n",
    "        \n",
    "#     datav2 = pd.read_csv(filename, sep=\" \", header=None)\n",
    "    \n",
    "#     datav2.columns = [filename]\n",
    "#     #filevals.append(filename)    \n",
    "#     for x in datav2[filename]:\n",
    "#         filevals.append(x)\n",
    "    \n",
    "#     arr[filecnt] = filevals  \n",
    "    \n",
    "    \n",
    "    \n",
    "#     name = filename.path[36:]\n",
    "#         #filenames[name] = {}\n",
    "#     sub = name.split('-')[0]\n",
    "#     lab = name[4:].split('-')[0]\n",
    "#     ind = int(name.split('-')[2][:-4])\n",
    "    \n",
    "#     if lab in [\"VT\", \"VFb\"] :\n",
    "#         bin = 1\n",
    "#     else:\n",
    "#         bin = 0\n",
    "    \n",
    "#     df2 = {'Subject Number': sub, 'Label': lab, 'Index': ind, 'Bin' : bin}\n",
    "    \n",
    "#     df = df.append(df2, ignore_index = True)\n",
    "    \n",
    "    \n",
    "#     #for x in range(len(filevales)):\n",
    "#      #   arr[filecnt][x] = filevals[x]\n",
    "    \n",
    "#     filecnt += 1\n",
    "    \n",
    "    \n",
    "# import numpy\n",
    "\n",
    "# newnumpy = numpy.array(arr)\n",
    "\n",
    "# largedf = pd.DataFrame(newnumpy)\n",
    "\n",
    "\n",
    "# alldf = pd.concat([df, largedf], axis = 1)\n",
    "\n",
    "# alldf = alldf.sort_values(by=['Subject Number', 'Label', 'Index'], ignore_index = True)\n",
    "# alldf = alldf.drop(columns=['Label', 'Index', 'Bin'])\n",
    "# #print(filecnt)\n",
    "\n",
    "# print(len(arr[0]))\n",
    "\n",
    "# #print(alldf.head())\n",
    "\n",
    "# onlylab = df.drop(columns=['Subject Number','Label', 'Index'])\n",
    "\n",
    "# finaldf = pd.concat([alldf, onlylab], axis = 1)\n",
    "\n",
    "# # print(finaldf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /device:CPU:0 || Unnamed device || CPU || 256.0 MiB\n",
      " /device:XLA_CPU:0 || Unnamed device || XLA_CPU || 16.0 GiB\n",
      " /device:XLA_GPU:0 || Unnamed device || XLA_GPU || 16.0 GiB\n",
      " /device:XLA_GPU:1 || Unnamed device || XLA_GPU || 16.0 GiB\n",
      " /device:XLA_GPU:2 || Unnamed device || XLA_GPU || 16.0 GiB\n",
      " /device:XLA_GPU:3 || Unnamed device || XLA_GPU || 16.0 GiB\n",
      " /device:GPU:0 ||  GeForce GTX 1080 Ti || GPU || 10.1 GiB\n",
      " /device:GPU:1 ||  GeForce GTX 1080 Ti || GPU || 10.1 GiB\n",
      " /device:GPU:2 ||  GeForce GTX 1080 Ti || GPU || 10.1 GiB\n",
      " /device:GPU:3 ||  GeForce GTX 1080 Ti || GPU || 10.1 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 01:19:43.296011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:19:43.297237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:19:43.298390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:19:43.299543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:19:43.299674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 01:19:43.299721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 01:19:43.299764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 01:19:43.299806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 01:19:43.299846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 01:19:43.299887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 01:19:43.299927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 01:19:43.305153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-10-05 01:19:43.305272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-05 01:19:43.305286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 \n",
      "2022-10-05 01:19:43.305293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y N N \n",
      "2022-10-05 01:19:43.305299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N N N \n",
      "2022-10-05 01:19:43.305305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N Y \n",
      "2022-10-05 01:19:43.305311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N Y N \n",
      "2022-10-05 01:19:43.308639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:0 with 10377 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:19:43.309480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:1 with 10378 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:19:43.310002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:2 with 10378 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:19:43.310658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:3 with 10378 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "devices = device_lib.list_local_devices()\n",
    "\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for d in devices:\n",
    "    t = d.device_type\n",
    "    name = d.physical_device_desc\n",
    "    l = [item.split(':',1) for item in name.split(\", \")]\n",
    "    name_attr = dict([x for x in l if len(x)==2])\n",
    "    dev = name_attr.get('name', 'Unnamed device')\n",
    "    print(f\" {d.name} || {dev} || {t} || {sizeof_fmt(d.memory_limit)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.read_csv('dataloaded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1241</th>\n",
       "      <th>1242</th>\n",
       "      <th>1243</th>\n",
       "      <th>1244</th>\n",
       "      <th>1245</th>\n",
       "      <th>1246</th>\n",
       "      <th>1247</th>\n",
       "      <th>1248</th>\n",
       "      <th>1249</th>\n",
       "      <th>Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S01</td>\n",
       "      <td>-0.001718</td>\n",
       "      <td>-0.095806</td>\n",
       "      <td>-0.164705</td>\n",
       "      <td>-0.189470</td>\n",
       "      <td>-0.105115</td>\n",
       "      <td>-0.007060</td>\n",
       "      <td>0.106121</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030358</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.003488</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>-0.017681</td>\n",
       "      <td>-0.020547</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>-0.030727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S01</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>-0.008247</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.018108</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S01</td>\n",
       "      <td>-0.012153</td>\n",
       "      <td>-0.019460</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>-0.011775</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>-0.014232</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.001435</td>\n",
       "      <td>-0.008413</td>\n",
       "      <td>-0.011103</td>\n",
       "      <td>-0.013496</td>\n",
       "      <td>-0.003475</td>\n",
       "      <td>-0.006173</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>-0.004514</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S01</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>-0.006620</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.023382</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002689</td>\n",
       "      <td>-0.004957</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>-0.020514</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>-0.009719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S01</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>-0.013933</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>-0.011752</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>-0.013597</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>-0.007044</td>\n",
       "      <td>0.031403</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.013153</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>-0.015965</td>\n",
       "      <td>-0.004866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30208</th>\n",
       "      <td>S95</td>\n",
       "      <td>-0.332482</td>\n",
       "      <td>-0.340718</td>\n",
       "      <td>-0.122615</td>\n",
       "      <td>0.085202</td>\n",
       "      <td>0.471829</td>\n",
       "      <td>0.630832</td>\n",
       "      <td>0.878892</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.016916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286388</td>\n",
       "      <td>0.065137</td>\n",
       "      <td>-0.055429</td>\n",
       "      <td>0.236196</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.186460</td>\n",
       "      <td>0.218980</td>\n",
       "      <td>0.200417</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30209</th>\n",
       "      <td>S95</td>\n",
       "      <td>-0.209928</td>\n",
       "      <td>-0.204724</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>-0.076489</td>\n",
       "      <td>0.087503</td>\n",
       "      <td>0.130825</td>\n",
       "      <td>-0.061206</td>\n",
       "      <td>0.190358</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884048</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.572090</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>-0.089960</td>\n",
       "      <td>-0.028005</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>-0.189498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30210</th>\n",
       "      <td>S95</td>\n",
       "      <td>-0.100085</td>\n",
       "      <td>-0.513255</td>\n",
       "      <td>-0.519358</td>\n",
       "      <td>-0.172858</td>\n",
       "      <td>0.384442</td>\n",
       "      <td>0.373873</td>\n",
       "      <td>0.129929</td>\n",
       "      <td>0.052760</td>\n",
       "      <td>-0.153613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057048</td>\n",
       "      <td>0.086446</td>\n",
       "      <td>0.377366</td>\n",
       "      <td>0.204054</td>\n",
       "      <td>0.256200</td>\n",
       "      <td>0.083140</td>\n",
       "      <td>0.221371</td>\n",
       "      <td>0.191867</td>\n",
       "      <td>-0.575213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30211</th>\n",
       "      <td>S95</td>\n",
       "      <td>0.131366</td>\n",
       "      <td>0.106964</td>\n",
       "      <td>0.050252</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168492</td>\n",
       "      <td>-0.126853</td>\n",
       "      <td>-0.022228</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>-0.120576</td>\n",
       "      <td>-0.155777</td>\n",
       "      <td>-0.108943</td>\n",
       "      <td>-0.158428</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30212</th>\n",
       "      <td>S95</td>\n",
       "      <td>0.205708</td>\n",
       "      <td>0.209226</td>\n",
       "      <td>-0.096537</td>\n",
       "      <td>-0.125522</td>\n",
       "      <td>-0.269852</td>\n",
       "      <td>-0.334346</td>\n",
       "      <td>-0.414996</td>\n",
       "      <td>-0.073428</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218360</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>-0.160720</td>\n",
       "      <td>0.088019</td>\n",
       "      <td>-0.029808</td>\n",
       "      <td>-0.082308</td>\n",
       "      <td>-0.119268</td>\n",
       "      <td>0.129305</td>\n",
       "      <td>-0.064128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30213 rows × 1252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subject Number         0         1         2         3         4  \\\n",
       "0                S01 -0.001718 -0.095806 -0.164705 -0.189470 -0.105115   \n",
       "1                S01  0.016251 -0.008247  0.005012 -0.007177 -0.000700   \n",
       "2                S01 -0.012153 -0.019460  0.010308 -0.011775  0.009485   \n",
       "3                S01  0.003189  0.009441  0.013109  0.004647 -0.006620   \n",
       "4                S01  0.012738  0.012978 -0.013933  0.013002 -0.011752   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "30208            S95 -0.332482 -0.340718 -0.122615  0.085202  0.471829   \n",
       "30209            S95 -0.209928 -0.204724  0.033302 -0.076489  0.087503   \n",
       "30210            S95 -0.100085 -0.513255 -0.519358 -0.172858  0.384442   \n",
       "30211            S95  0.131366  0.106964  0.050252  0.196197  0.027283   \n",
       "30212            S95  0.205708  0.209226 -0.096537 -0.125522 -0.269852   \n",
       "\n",
       "              5         6         7         8  ...      1241      1242  \\\n",
       "0     -0.007060  0.106121  0.127848  0.111724  ...  0.030358  0.023003   \n",
       "1     -0.018108  0.017456 -0.013712  0.010719  ... -0.018446  0.001842   \n",
       "2      0.017778 -0.014232  0.006212  0.010179  ... -0.002355 -0.001435   \n",
       "3     -0.004719  0.002988 -0.023382  0.007880  ... -0.002689 -0.004957   \n",
       "4      0.007639 -0.013597 -0.000866  0.000694  ...  0.013919 -0.007044   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "30208  0.630832  0.878892  0.443409  0.016916  ... -0.286388  0.065137   \n",
       "30209  0.130825 -0.061206  0.190358  0.185017  ...  0.884048  0.793466   \n",
       "30210  0.373873  0.129929  0.052760 -0.153613  ...  0.057048  0.086446   \n",
       "30211  0.046262  0.035980  0.093962  0.019785  ...  0.168492 -0.126853   \n",
       "30212 -0.334346 -0.414996 -0.073428  0.111627  ... -0.218360  0.073458   \n",
       "\n",
       "           1243      1244      1245      1246      1247      1248      1249  \\\n",
       "0     -0.007709 -0.003488  0.014278 -0.017681 -0.020547 -0.001652 -0.030727   \n",
       "1      0.005302  0.011047  0.017912  0.021195 -0.001553  0.033582  0.024117   \n",
       "2     -0.008413 -0.011103 -0.013496 -0.003475 -0.006173  0.002482 -0.004514   \n",
       "3      0.009094  0.013103 -0.012610 -0.020514  0.006492 -0.006451 -0.009719   \n",
       "4      0.031403  0.012673 -0.003761 -0.013153 -0.012249 -0.015965 -0.004866   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30208 -0.055429  0.236196  0.063671  0.186460  0.218980  0.200417  0.070140   \n",
       "30209  0.572090  0.089591 -0.089960 -0.028005 -0.161846  0.027143 -0.189498   \n",
       "30210  0.377366  0.204054  0.256200  0.083140  0.221371  0.191867 -0.575213   \n",
       "30211 -0.022228  0.005178 -0.120576 -0.155777 -0.108943 -0.158428  0.006180   \n",
       "30212 -0.160720  0.088019 -0.029808 -0.082308 -0.119268  0.129305 -0.064128   \n",
       "\n",
       "       Bin  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "30208  1.0  \n",
       "30209  1.0  \n",
       "30210  1.0  \n",
       "30211  1.0  \n",
       "30212  1.0  \n",
       "\n",
       "[30213 rows x 1252 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "GPUS = [\"GPU:0\",\"GPU:1\", \"GPU:2\",\"GPU:3\"]\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy( GPUS )\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "\n",
    "batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    16253\n",
       "1.0    13960\n",
       "Name: Bin, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.Bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf_new  = finaldf.drop(columns=['Subject Number'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1241</th>\n",
       "      <th>1242</th>\n",
       "      <th>1243</th>\n",
       "      <th>1244</th>\n",
       "      <th>1245</th>\n",
       "      <th>1246</th>\n",
       "      <th>1247</th>\n",
       "      <th>1248</th>\n",
       "      <th>1249</th>\n",
       "      <th>Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001718</td>\n",
       "      <td>-0.095806</td>\n",
       "      <td>-0.164705</td>\n",
       "      <td>-0.189470</td>\n",
       "      <td>-0.105115</td>\n",
       "      <td>-0.007060</td>\n",
       "      <td>0.106121</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>0.061645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030358</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.003488</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>-0.017681</td>\n",
       "      <td>-0.020547</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>-0.030727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016251</td>\n",
       "      <td>-0.008247</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.018108</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012153</td>\n",
       "      <td>-0.019460</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>-0.011775</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>-0.014232</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.001435</td>\n",
       "      <td>-0.008413</td>\n",
       "      <td>-0.011103</td>\n",
       "      <td>-0.013496</td>\n",
       "      <td>-0.003475</td>\n",
       "      <td>-0.006173</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>-0.004514</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>-0.006620</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.023382</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002689</td>\n",
       "      <td>-0.004957</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>-0.020514</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>-0.009719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>-0.013933</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>-0.011752</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>-0.013597</td>\n",
       "      <td>-0.000866</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>-0.007044</td>\n",
       "      <td>0.031403</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.013153</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>-0.015965</td>\n",
       "      <td>-0.004866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30208</th>\n",
       "      <td>-0.332482</td>\n",
       "      <td>-0.340718</td>\n",
       "      <td>-0.122615</td>\n",
       "      <td>0.085202</td>\n",
       "      <td>0.471829</td>\n",
       "      <td>0.630832</td>\n",
       "      <td>0.878892</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.016916</td>\n",
       "      <td>-0.467942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286388</td>\n",
       "      <td>0.065137</td>\n",
       "      <td>-0.055429</td>\n",
       "      <td>0.236196</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.186460</td>\n",
       "      <td>0.218980</td>\n",
       "      <td>0.200417</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30209</th>\n",
       "      <td>-0.209928</td>\n",
       "      <td>-0.204724</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>-0.076489</td>\n",
       "      <td>0.087503</td>\n",
       "      <td>0.130825</td>\n",
       "      <td>-0.061206</td>\n",
       "      <td>0.190358</td>\n",
       "      <td>0.185017</td>\n",
       "      <td>0.133373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884048</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.572090</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>-0.089960</td>\n",
       "      <td>-0.028005</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>-0.189498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30210</th>\n",
       "      <td>-0.100085</td>\n",
       "      <td>-0.513255</td>\n",
       "      <td>-0.519358</td>\n",
       "      <td>-0.172858</td>\n",
       "      <td>0.384442</td>\n",
       "      <td>0.373873</td>\n",
       "      <td>0.129929</td>\n",
       "      <td>0.052760</td>\n",
       "      <td>-0.153613</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057048</td>\n",
       "      <td>0.086446</td>\n",
       "      <td>0.377366</td>\n",
       "      <td>0.204054</td>\n",
       "      <td>0.256200</td>\n",
       "      <td>0.083140</td>\n",
       "      <td>0.221371</td>\n",
       "      <td>0.191867</td>\n",
       "      <td>-0.575213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30211</th>\n",
       "      <td>0.131366</td>\n",
       "      <td>0.106964</td>\n",
       "      <td>0.050252</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>0.028760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168492</td>\n",
       "      <td>-0.126853</td>\n",
       "      <td>-0.022228</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>-0.120576</td>\n",
       "      <td>-0.155777</td>\n",
       "      <td>-0.108943</td>\n",
       "      <td>-0.158428</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30212</th>\n",
       "      <td>0.205708</td>\n",
       "      <td>0.209226</td>\n",
       "      <td>-0.096537</td>\n",
       "      <td>-0.125522</td>\n",
       "      <td>-0.269852</td>\n",
       "      <td>-0.334346</td>\n",
       "      <td>-0.414996</td>\n",
       "      <td>-0.073428</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218360</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>-0.160720</td>\n",
       "      <td>0.088019</td>\n",
       "      <td>-0.029808</td>\n",
       "      <td>-0.082308</td>\n",
       "      <td>-0.119268</td>\n",
       "      <td>0.129305</td>\n",
       "      <td>-0.064128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30213 rows × 1251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.001718 -0.095806 -0.164705 -0.189470 -0.105115 -0.007060  0.106121   \n",
       "1      0.016251 -0.008247  0.005012 -0.007177 -0.000700 -0.018108  0.017456   \n",
       "2     -0.012153 -0.019460  0.010308 -0.011775  0.009485  0.017778 -0.014232   \n",
       "3      0.003189  0.009441  0.013109  0.004647 -0.006620 -0.004719  0.002988   \n",
       "4      0.012738  0.012978 -0.013933  0.013002 -0.011752  0.007639 -0.013597   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30208 -0.332482 -0.340718 -0.122615  0.085202  0.471829  0.630832  0.878892   \n",
       "30209 -0.209928 -0.204724  0.033302 -0.076489  0.087503  0.130825 -0.061206   \n",
       "30210 -0.100085 -0.513255 -0.519358 -0.172858  0.384442  0.373873  0.129929   \n",
       "30211  0.131366  0.106964  0.050252  0.196197  0.027283  0.046262  0.035980   \n",
       "30212  0.205708  0.209226 -0.096537 -0.125522 -0.269852 -0.334346 -0.414996   \n",
       "\n",
       "              7         8         9  ...      1241      1242      1243  \\\n",
       "0      0.127848  0.111724  0.061645  ...  0.030358  0.023003 -0.007709   \n",
       "1     -0.013712  0.010719  0.010638  ... -0.018446  0.001842  0.005302   \n",
       "2      0.006212  0.010179  0.000313  ... -0.002355 -0.001435 -0.008413   \n",
       "3     -0.023382  0.007880  0.019491  ... -0.002689 -0.004957  0.009094   \n",
       "4     -0.000866  0.000694  0.000275  ...  0.013919 -0.007044  0.031403   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "30208  0.443409  0.016916 -0.467942  ... -0.286388  0.065137 -0.055429   \n",
       "30209  0.190358  0.185017  0.133373  ...  0.884048  0.793466  0.572090   \n",
       "30210  0.052760 -0.153613  0.025636  ...  0.057048  0.086446  0.377366   \n",
       "30211  0.093962  0.019785  0.028760  ...  0.168492 -0.126853 -0.022228   \n",
       "30212 -0.073428  0.111627  0.309735  ... -0.218360  0.073458 -0.160720   \n",
       "\n",
       "           1244      1245      1246      1247      1248      1249  Bin  \n",
       "0     -0.003488  0.014278 -0.017681 -0.020547 -0.001652 -0.030727  0.0  \n",
       "1      0.011047  0.017912  0.021195 -0.001553  0.033582  0.024117  0.0  \n",
       "2     -0.011103 -0.013496 -0.003475 -0.006173  0.002482 -0.004514  0.0  \n",
       "3      0.013103 -0.012610 -0.020514  0.006492 -0.006451 -0.009719  0.0  \n",
       "4      0.012673 -0.003761 -0.013153 -0.012249 -0.015965 -0.004866  0.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "30208  0.236196  0.063671  0.186460  0.218980  0.200417  0.070140  1.0  \n",
       "30209  0.089591 -0.089960 -0.028005 -0.161846  0.027143 -0.189498  1.0  \n",
       "30210  0.204054  0.256200  0.083140  0.221371  0.191867 -0.575213  1.0  \n",
       "30211  0.005178 -0.120576 -0.155777 -0.108943 -0.158428  0.006180  1.0  \n",
       "30212  0.088019 -0.029808 -0.082308 -0.119268  0.129305 -0.064128  1.0  \n",
       "\n",
       "[30213 rows x 1251 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finaldf_new.drop(columns=finaldf.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finaldf_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1241</th>\n",
       "      <th>1242</th>\n",
       "      <th>1243</th>\n",
       "      <th>1244</th>\n",
       "      <th>1245</th>\n",
       "      <th>1246</th>\n",
       "      <th>1247</th>\n",
       "      <th>1248</th>\n",
       "      <th>1249</th>\n",
       "      <th>Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26550</th>\n",
       "      <td>-0.049597</td>\n",
       "      <td>0.088178</td>\n",
       "      <td>0.049893</td>\n",
       "      <td>0.205729</td>\n",
       "      <td>0.169830</td>\n",
       "      <td>0.127879</td>\n",
       "      <td>-0.011196</td>\n",
       "      <td>-0.150814</td>\n",
       "      <td>-0.021235</td>\n",
       "      <td>-0.082136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518090</td>\n",
       "      <td>-0.281975</td>\n",
       "      <td>-0.369579</td>\n",
       "      <td>-0.234193</td>\n",
       "      <td>-0.027395</td>\n",
       "      <td>0.045427</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>0.252902</td>\n",
       "      <td>0.276412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.019049</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>-0.011859</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>-0.012151</td>\n",
       "      <td>-0.004783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>-0.006361</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>-0.011860</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.069906</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.046337</td>\n",
       "      <td>-0.069642</td>\n",
       "      <td>-0.035936</td>\n",
       "      <td>-0.075132</td>\n",
       "      <td>-0.022700</td>\n",
       "      <td>-0.065040</td>\n",
       "      <td>-0.090904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034172</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.050401</td>\n",
       "      <td>-0.039538</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>-0.009303</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.053426</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.032794</td>\n",
       "      <td>0.016205</td>\n",
       "      <td>-0.040452</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>0.025697</td>\n",
       "      <td>0.061529</td>\n",
       "      <td>0.070869</td>\n",
       "      <td>-0.080447</td>\n",
       "      <td>0.017260</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023979</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>0.024009</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>0.066466</td>\n",
       "      <td>-0.036463</td>\n",
       "      <td>-0.097612</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>-0.019717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19823</th>\n",
       "      <td>0.053036</td>\n",
       "      <td>-0.003026</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>-0.066557</td>\n",
       "      <td>0.060273</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>-0.048757</td>\n",
       "      <td>0.030638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005230</td>\n",
       "      <td>-0.051545</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>-0.063048</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>0.041983</td>\n",
       "      <td>0.086108</td>\n",
       "      <td>-0.038835</td>\n",
       "      <td>0.078036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>-0.022839</td>\n",
       "      <td>0.078566</td>\n",
       "      <td>0.042846</td>\n",
       "      <td>0.077579</td>\n",
       "      <td>0.146550</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.051523</td>\n",
       "      <td>-0.012925</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>-0.052274</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.087628</td>\n",
       "      <td>0.122839</td>\n",
       "      <td>0.078319</td>\n",
       "      <td>0.119856</td>\n",
       "      <td>0.168392</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>-0.023270</td>\n",
       "      <td>0.063335</td>\n",
       "      <td>-0.058871</td>\n",
       "      <td>0.033884</td>\n",
       "      <td>-0.014279</td>\n",
       "      <td>0.031518</td>\n",
       "      <td>-0.045016</td>\n",
       "      <td>-0.029214</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047777</td>\n",
       "      <td>-0.037244</td>\n",
       "      <td>-0.014752</td>\n",
       "      <td>0.037522</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>-0.010653</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>-0.016830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.025420</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.029728</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>-0.021339</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.012520</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.042817</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12384</th>\n",
       "      <td>0.089430</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>0.043512</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>-0.010954</td>\n",
       "      <td>-0.036403</td>\n",
       "      <td>-0.029401</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>-0.030841</td>\n",
       "      <td>-0.064240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080091</td>\n",
       "      <td>-0.046039</td>\n",
       "      <td>-0.071557</td>\n",
       "      <td>-0.015626</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.062330</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>-0.009975</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13965</th>\n",
       "      <td>0.017739</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>-0.020507</td>\n",
       "      <td>-0.003545</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>-0.017539</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>-0.033977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037204</td>\n",
       "      <td>0.039354</td>\n",
       "      <td>0.028899</td>\n",
       "      <td>-0.021899</td>\n",
       "      <td>0.030888</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.035854</td>\n",
       "      <td>-0.008927</td>\n",
       "      <td>-0.025850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30213 rows × 1251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "26550 -0.049597  0.088178  0.049893  0.205729  0.169830  0.127879 -0.011196   \n",
       "10626  0.015317  0.019049 -0.013178 -0.011859  0.001878  0.001854  0.006976   \n",
       "918    0.069906  0.001842  0.001821  0.046337 -0.069642 -0.035936 -0.075132   \n",
       "936    0.032794  0.016205 -0.040452 -0.021639  0.025697  0.061529  0.070869   \n",
       "19823  0.053036 -0.003026  0.003333  0.007222 -0.066557  0.060273  0.061204   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "9471  -0.022839  0.078566  0.042846  0.077579  0.146550  0.093407  0.051523   \n",
       "20305 -0.023270  0.063335 -0.058871  0.033884 -0.014279  0.031518 -0.045016   \n",
       "10044  0.006957  0.025420  0.016457  0.029728  0.004763 -0.004699  0.012927   \n",
       "12384  0.089430  0.093786  0.043512  0.007107 -0.010954 -0.036403 -0.029401   \n",
       "13965  0.017739  0.003353 -0.006033 -0.020507 -0.003545  0.028344 -0.017539   \n",
       "\n",
       "              7         8         9  ...      1241      1242      1243  \\\n",
       "26550 -0.150814 -0.021235 -0.082136  ... -0.518090 -0.281975 -0.369579   \n",
       "10626 -0.007244 -0.012151 -0.004783  ...  0.004740 -0.006361  0.012527   \n",
       "918   -0.022700 -0.065040 -0.090904  ... -0.034172  0.016380  0.050401   \n",
       "936   -0.080447  0.017260 -0.002036  ...  0.023979  0.018226  0.024009   \n",
       "19823 -0.001411 -0.048757  0.030638  ... -0.005230 -0.051545  0.036089   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "9471  -0.012925  0.009944  0.020469  ... -0.116460  0.008033 -0.052274   \n",
       "20305 -0.029214 -0.010250  0.023075  ... -0.047777 -0.037244 -0.014752   \n",
       "10044  0.016898 -0.021339  0.029310  ... -0.014069  0.013130 -0.000337   \n",
       "12384 -0.033764 -0.030841 -0.064240  ... -0.080091 -0.046039 -0.071557   \n",
       "13965  0.033658  0.010706 -0.033977  ...  0.037204  0.039354  0.028899   \n",
       "\n",
       "           1244      1245      1246      1247      1248      1249  Bin  \n",
       "26550 -0.234193 -0.027395  0.045427  0.009423  0.252902  0.276412  1.0  \n",
       "10626  0.021302 -0.014129 -0.011860 -0.009129  0.000928  0.022446  0.0  \n",
       "918   -0.039538  0.048488 -0.009303 -0.001823 -0.053426 -0.009273  0.0  \n",
       "936   -0.004098  0.066466 -0.036463 -0.097612  0.041293 -0.019717  0.0  \n",
       "19823 -0.063048  0.013845  0.041983  0.086108 -0.038835  0.078036  0.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "9471   0.032513  0.087628  0.122839  0.078319  0.119856  0.168392  0.0  \n",
       "20305  0.037522  0.030576 -0.010653  0.043200  0.002813 -0.016830  0.0  \n",
       "10044 -0.012520  0.004679  0.042817  0.001694  0.039117  0.022760  0.0  \n",
       "12384 -0.015626  0.000532  0.062330  0.015866 -0.009975 -0.025286  1.0  \n",
       "13965 -0.021899  0.030888  0.003050  0.035854 -0.008927 -0.025850  0.0  \n",
       "\n",
       "[30213 rows x 1251 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf_new.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = finaldf_new.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = finaldf_new.iloc[:,1250].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_n, X_rem, y_train, y_rem,= train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "# X_train, X_rem, y_train, y_rem,= train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "X_train_n, X_test_n, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid_n, X_test_n, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state = 0)\n",
    "# X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24170, 1250)\n",
      "(24170,)\n",
      "(6043, 1250)\n",
      "(6043,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_n.shape), print(y_train.shape)\n",
    "# print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test_n.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_n = scaler.fit_transform(X_train)\n",
    "# X_test_n = scaler.transform(X_test)\n",
    "# # X_valid_n = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.reshape(X_train_n, (X_train_n.shape[0], X_train_n.shape[1],1))\n",
    "X_test_cnn = np.reshape(X_test_n, (X_test_n.shape[0], X_test_n.shape[1],1))\n",
    "# X_valid_cnn = np.reshape(X_valid_n, (X_valid_n.shape[0], X_valid_n.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24170, 1250, 1), (6043, 1250, 1))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_cnn.shape, X_test_cnn.shape, X_valid_cnn.shape \n",
    "X_train_cnn.shape, X_test_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_timesteps, n_features = X_train_cnn.shape[1], X_train_cnn.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoint_path/training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('./checkpoint_path/training_1/model{epoch:08d}.h5',save_freq='epoch', period=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = np.shape(X_train_cnn)\n",
    "# input_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape=(X_train_n.shape[-1],)\n",
    "# input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=16, kernel_size=3, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(Conv1D(filters=16, kernel_size=4, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(Conv1D(filters=16, kernel_size=5, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#########Best################\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=16, kernel_size=5,strides=5, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(Conv1D(filters=8, kernel_size=3,strides=3, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(Conv1D(filters=4, kernel_size=5,strides=2, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=5,strides=5, activation='relu',input_shape = (1250,1)))\n",
    "model.add(Conv1D(filters=8, kernel_size=3,strides=3, activation='relu',input_shape = (1250,1)))\n",
    "model.add(Conv1D(filters=4, kernel_size=2,strides=2, activation='relu',input_shape = (1250,1)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "# with strategy.scope():\n",
    "#     model = Sequential()\n",
    "#     # adding the first convolutionial layer with 24 filters and 2 by 1 kernal size, using the rectifier as the activation function\n",
    "#     model.add(Conv2D(24, (16,1),input_shape=(24170, 1250, 1),activation='relu'))\n",
    "#     # adding a maxpooling layer\n",
    "#     model.add(MaxPooling2D(pool_size=(2,1),strides=(2,1),padding='valid'))\n",
    "#     # flattening the output in order to apply the fully connected layer\n",
    "#     model.add(Flatten())\n",
    "#     # adding first fully connected layer with 12 units\n",
    "#     model.add(Dense(12, activation='relu')) \n",
    "#     # adding the dropout layer to avoid overfitting\n",
    "#     model.add(Dropout(0.3))\n",
    "#     # adding softmax layer for the classification\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     # Compiling the model to generate a model\n",
    "\n",
    "#     adam = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train_cnn, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "# elapsed = time.time()-start\n",
    "# print (f'Training time: {hms_string(elapsed)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(1250,1)))\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(len(np.unique(y_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=128, kernel_size=5, activation='relu',input_shape = (1250,1)))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# # model.add(LSTM(32))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 250, 16)           96        \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 83, 8)             392       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 41, 4)             68        \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 41, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 164)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 165       \n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam = optimizers.SGD(lr=0.001,decay=1e-6, momentum=0.9, nesterov=True) \n",
    "# adam = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.6141 - accuracy: 0.6738\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.5629 - accuracy: 0.7432\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.5166 - accuracy: 0.7883\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.4685 - accuracy: 0.8133\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.4380 - accuracy: 0.8257\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.4113 - accuracy: 0.8359\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8443\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3743 - accuracy: 0.8473\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3584 - accuracy: 0.8530\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3446 - accuracy: 0.8595\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3361 - accuracy: 0.8627\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3238 - accuracy: 0.8715\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3119 - accuracy: 0.8731\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3127 - accuracy: 0.8713\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.3027 - accuracy: 0.8792\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.2975 - accuracy: 0.8789\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.2935 - accuracy: 0.8793\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.2868 - accuracy: 0.8837\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.2867 - accuracy: 0.8835\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 3s 4ms/step - loss: 0.2812 - accuracy: 0.8880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a8c76ef40>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train_cnn, y_train, validation_data = (X_valid_cnn, y_valid),epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "model.fit(X_train_cnn, y_train, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf.saved_model.save(model, \"/data/space1/BooleanLab/TinyML/saved-model_5\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model, open('./checkpoint_path/training_1/best_model_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./checkpoint_path/training_1/best_model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9834984 ],\n",
       "       [0.33614033],\n",
       "       [0.9756118 ],\n",
       "       ...,\n",
       "       [0.99999547],\n",
       "       [0.99708444],\n",
       "       [0.4839402 ]], dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = model.predict_classes(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9262264846919955"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(y_test, y_pred_class)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.926\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.875\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8752178459393517"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = recall_score(y_test, y_pred_class)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.908\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.900\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2974,  200],\n",
       "       [ 358, 2511]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076617574052623"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.94      0.91      3174\n",
      "         1.0       0.93      0.88      0.90      2869\n",
      "\n",
      "    accuracy                           0.91      6043\n",
      "   macro avg       0.91      0.91      0.91      6043\n",
      "weighted avg       0.91      0.91      0.91      6043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92775143, 0.88496511])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred_class, average=None, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta = (1+beta**2) * (p * r) / ((beta**2)*p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849651089025163"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_cnn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = X_train_cnn.shape[0] \n",
    "end_step = np.ceil(num_train_data / 32).astype(np.int32) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gputest/.conda/envs/tf_amitash/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:201: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv1d ( (None, 1235, 24)          794       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout  (None, 1235, 24)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 29640)             1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_3  (None, 1)                 59283     \n",
      "=================================================================\n",
      "Total params: 60,079\n",
      "Trainable params: 30,049\n",
      "Non-trainable params: 30,030\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 01:25:39.822603: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-10-05 01:25:39.822834: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED\n",
      "2022-10-05 01:25:39.824704: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED\n",
      "2022-10-05 01:25:39.824778: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 26/756 [>.............................] - ETA: 5s - loss: 0.5582 - accuracy: 0.8702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 01:25:40.897850: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-10-05 01:25:40.897933: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_NOT_INITIALIZED\n",
      "2022-10-05 01:25:40.898084: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI_ERROR_NOT_INITIALIZED\n",
      "2022-10-05 01:25:40.904820: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI_ERROR_INVALID_PARAMETER\n",
      "2022-10-05 01:25:40.905106: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 0 callback api events and 0 activity events.\n",
      "2022-10-05 01:25:40.907813: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40\n",
      "2022-10-05 01:25:40.908402: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40/gene-gpu.trace.json.gz\n",
      "2022-10-05 01:25:40.908790: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0 ms\n",
      "\n",
      "2022-10-05 01:25:40.909127: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40Dumped tool data for overview_page.pb to /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40/gene-gpu.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40/gene-gpu.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40/gene-gpu.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /tmp/tmpld9ifchq/train/plugins/profile/2022_10_05_01_25_40/gene-gpu.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5746 - accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5734 - accuracy: 0.8852\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5747 - accuracy: 0.8827\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5744 - accuracy: 0.8843\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5740 - accuracy: 0.8845\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5739 - accuracy: 0.8833\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5758 - accuracy: 0.8788\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5748 - accuracy: 0.8809\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5750 - accuracy: 0.8813\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5759 - accuracy: 0.8773\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5755 - accuracy: 0.8788\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5743 - accuracy: 0.8827\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5745 - accuracy: 0.8815\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5733 - accuracy: 0.8849\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5740 - accuracy: 0.8839\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5738 - accuracy: 0.8833\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5746 - accuracy: 0.8806\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5742 - accuracy: 0.8817\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5745 - accuracy: 0.8804\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 4s 5ms/step - loss: 0.5742 - accuracy: 0.8810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a8cba6c70>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train_cnn, y_train, epochs=20, batch_size=32, verbose=1, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_for_pruning.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02805084],\n",
       "       [0.86258537],\n",
       "       [0.9990305 ],\n",
       "       ...,\n",
       "       [1.        ],\n",
       "       [0.99999964],\n",
       "       [0.20160383]], dtype=float32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = model_for_pruning.predict_classes(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276990718124084"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = precision_score(y_test, y_pred_class)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.928\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.662\n"
     ]
    }
   ],
   "source": [
    "print('Recall: %.3f' % recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6619031021261763"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = recall_score(y_test, y_pred_class)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.773\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3026,  148],\n",
       "       [ 970, 1899]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149925533675327"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.95      0.84      3174\n",
      "         1.0       0.93      0.66      0.77      2869\n",
      "\n",
      "    accuracy                           0.81      6043\n",
      "   macro avg       0.84      0.81      0.81      6043\n",
      "weighted avg       0.84      0.81      0.81      6043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90642224, 0.7021371 ])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred_class, average=None, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model_for_pruning, \"/data/space1/BooleanLab/TinyML/saved-model_prune\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/space1/BooleanLab/TinyML/test_prune/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/space1/BooleanLab/TinyML/test_prune/assets\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model)\n",
    "\n",
    "# _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "# _, pruned_keras_file = \"/data/space1/BooleanLab/TinyML/test_prune.h5\"\n",
    "# tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "tf.keras.models.save_model(model_for_export, \"/data/space1/BooleanLab/TinyML/test_prune\", include_optimizer=False)\n",
    "# print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 01:27:44.676404: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 4\n",
      "2022-10-05 01:27:44.676628: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2022-10-05 01:27:44.677787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.678353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.678909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.679450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.679561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 01:27:44.679596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 01:27:44.679629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 01:27:44.679654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 01:27:44.679681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 01:27:44.679704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 01:27:44.679732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 01:27:44.683751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-10-05 01:27:44.683837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-05 01:27:44.683844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 \n",
      "2022-10-05 01:27:44.683849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y N N \n",
      "2022-10-05 01:27:44.683852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N N N \n",
      "2022-10-05 01:27:44.683856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N Y \n",
      "2022-10-05 01:27:44.683859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N Y N \n",
      "2022-10-05 01:27:44.686447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10377 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.687021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10378 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.687585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10378 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.688142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10378 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.691567: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
      "2022-10-05 01:27:44.691583: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "2022-10-05 01:27:44.691588: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "2022-10-05 01:27:44.717544: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 4\n",
      "2022-10-05 01:27:44.717625: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2022-10-05 01:27:44.718522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.719068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.719603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.720133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 01:27:44.720186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 01:27:44.720205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 01:27:44.720221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 01:27:44.720236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 01:27:44.720251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 01:27:44.720267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 01:27:44.720283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 01:27:44.724205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-10-05 01:27:44.724249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-05 01:27:44.724255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 \n",
      "2022-10-05 01:27:44.724260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y N N \n",
      "2022-10-05 01:27:44.724263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N N N \n",
      "2022-10-05 01:27:44.724266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N Y \n",
      "2022-10-05 01:27:44.724270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N Y N \n",
      "2022-10-05 01:27:44.726752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10377 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.727305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10378 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.727847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10378 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.728390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10378 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2022-10-05 01:27:44.733497: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
      "2022-10-05 01:27:44.733511: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (-6), 17 edges (-6), time = 1.464ms.\n",
      "2022-10-05 01:27:44.733515: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 17 edges (0), time = 0.357ms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /tmp/tmpk_glji1z.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped pruned TFlite model: 37196.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "# print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 02:55:47.191756: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 4\n",
      "2022-10-05 02:55:47.191948: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2022-10-05 02:55:47.193152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.193764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.194369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.194973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.195060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 02:55:47.195087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 02:55:47.195116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 02:55:47.195140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 02:55:47.195164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 02:55:47.195189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 02:55:47.195214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 02:55:47.199484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-10-05 02:55:47.199573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-05 02:55:47.199580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 \n",
      "2022-10-05 02:55:47.199585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y N N \n",
      "2022-10-05 02:55:47.199589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N N N \n",
      "2022-10-05 02:55:47.199592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N Y \n",
      "2022-10-05 02:55:47.199595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N Y N \n",
      "2022-10-05 02:55:47.202542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10377 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.203163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10378 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.203772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10378 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.204365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10378 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.207996: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
      "2022-10-05 02:55:47.208011: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "2022-10-05 02:55:47.208015: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "2022-10-05 02:55:47.276487: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 4\n",
      "2022-10-05 02:55:47.276561: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2022-10-05 02:55:47.277496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.278041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.278575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.279111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 02:55:47.279158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 02:55:47.279176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 02:55:47.279191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 02:55:47.279206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 02:55:47.279221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 02:55:47.279236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 02:55:47.279252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 02:55:47.283224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-10-05 02:55:47.283266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-05 02:55:47.283272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 \n",
      "2022-10-05 02:55:47.283276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y N N \n",
      "2022-10-05 02:55:47.283279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N N N \n",
      "2022-10-05 02:55:47.283283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   N N N Y \n",
      "2022-10-05 02:55:47.283286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   N N Y N \n",
      "2022-10-05 02:55:47.286855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10377 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.287409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10378 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.287951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10378 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.288498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10378 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2022-10-05 02:55:47.293819: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
      "2022-10-05 02:55:47.293833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 34 nodes (-14), 33 edges (-14), time = 1.573ms.\n",
      "2022-10-05 02:55:47.293837: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 34 nodes (0), 33 edges (0), time = 0.466ms.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "# _, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(\"/data/space1/BooleanLab/TinyML/final2.tflite\", 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "# print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "# # print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "# print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_amitash')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd416bf6c5a6ea162befb13fc556bf41f1790754173e04a5a57317908e94683e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
